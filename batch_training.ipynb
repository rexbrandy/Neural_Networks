{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObwpHRzJf2y/FSQfqDOqWq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rexbrandy/Neural_Networks/blob/main/batch_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch Training\n",
        "\n",
        "In this we create a basic Dataset module to better understand how datasets and dataloaders are used.\n",
        "\n",
        "A dataloader is used to create smaller batches of data that can be iterated over. By performing the forward and backward pass on smaller batches of data we can adjust our gradients and weights more frequently and improve training speeds.\n",
        "\n",
        "### Terms to know\n",
        " - epoch: 1 forward and backward pass of ALL training samples\n",
        " - batch_size: number of training samples in one forward and backward pass\n",
        " - number of iteratons: number of passes, each pass using [batch_size] number of samples\n",
        "\n",
        "e.g 100 samples, batch_size=20 -> 100/20 = 5 iterations for 1 epoch"
      ],
      "metadata": {
        "id": "OtDzfYkXe3jc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZsgBilgefIi",
        "outputId": "cb7b6a3f-d312-4558-f679-4d0be8cc40ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1/2, step: 5/45, inputs: torch.Size([4, 13])\n",
            "epoch: 1/2, step: 10/45, inputs: torch.Size([4, 13])\n",
            "epoch: 1/2, step: 15/45, inputs: torch.Size([4, 13])\n",
            "epoch: 1/2, step: 20/45, inputs: torch.Size([4, 13])\n",
            "epoch: 1/2, step: 25/45, inputs: torch.Size([4, 13])\n",
            "epoch: 1/2, step: 30/45, inputs: torch.Size([4, 13])\n",
            "epoch: 1/2, step: 35/45, inputs: torch.Size([4, 13])\n",
            "epoch: 1/2, step: 40/45, inputs: torch.Size([4, 13])\n",
            "epoch: 1/2, step: 45/45, inputs: torch.Size([2, 13])\n",
            "epoch: 2/2, step: 5/45, inputs: torch.Size([4, 13])\n",
            "epoch: 2/2, step: 10/45, inputs: torch.Size([4, 13])\n",
            "epoch: 2/2, step: 15/45, inputs: torch.Size([4, 13])\n",
            "epoch: 2/2, step: 20/45, inputs: torch.Size([4, 13])\n",
            "epoch: 2/2, step: 25/45, inputs: torch.Size([4, 13])\n",
            "epoch: 2/2, step: 30/45, inputs: torch.Size([4, 13])\n",
            "epoch: 2/2, step: 35/45, inputs: torch.Size([4, 13])\n",
            "epoch: 2/2, step: 40/45, inputs: torch.Size([4, 13])\n",
            "epoch: 2/2, step: 45/45, inputs: torch.Size([2, 13])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "    '''\n",
        "        This is an example of a custom Dataset module \n",
        "        that inherits the torch.utils.data.Dataset class\n",
        "    '''\n",
        "    def __init__(self, file_name=None):\n",
        "        if file_name is None:\n",
        "            file_name = './data/wine.csv'\n",
        "\n",
        "        xy = np.loadtxt(file_name, delimiter=',', dtype=np.float32, skiprows=1)\n",
        "        self.x = torch.from_numpy(xy[:, 1:])# every row and from every row the 1st to last elements\n",
        "        self.y = torch.from_numpy(xy[:, [0]])# every row and just the 0th element\n",
        "        self.n_samples = xy.shape[0]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        # access class via index: dataset[0]\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        # override len(): len(dataset)\n",
        "        return self.n_samples\n",
        "\n",
        "dataset = WineDataset()\n",
        "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/4)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(dataloader):\n",
        "        if (i+1) %  5 == 0:\n",
        "            print(f'epoch: {epoch+1}/{num_epochs}, step: {i+1}/{n_iterations}, inputs: {inputs.shape}')\n"
      ]
    }
  ]
}